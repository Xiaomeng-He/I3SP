{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import sort_log, debiasing, mapping_case_id, add_soc_eoc,\\\n",
    "    create_time_features, train_log_normalize, test_log_normalize,\\\n",
    "    train_mapping_event_name, test_mapping_event_name\n",
    "from train_test_split import get_train_test_split_point, get_discard_case_list, \\\n",
    "    create_table_without_discard_case, get_train_val_case_list\n",
    "from create_prefix_suffix import create_log_prefix, create_trace_prefix, \\\n",
    "create_trace_suffix, create_log_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPIC2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '.../BPIC2017.csv'\n",
    "start_date = None\n",
    "end_date = '2017-01'\n",
    "max_duration = 47.81\n",
    "max_len = 87\n",
    "\n",
    "num_act =\n",
    "trace_prefix_len = 88 # max_len + 1 (SOC)\n",
    "trace_prefix_len = 88 # max_len + 1 (EOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPIC2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '.../BPIC2019.csv'\n",
    "start_date = '2018-01'\n",
    "end_date = '2019-02'\n",
    "max_duration = 143.33\n",
    "max_len = 13\n",
    "\n",
    "num_act =\n",
    "trace_prefix_len =\n",
    "trace_prefix_len ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '.../BAC.csv'\n",
    "start_date = None\n",
    "end_date = None\n",
    "max_duration = \n",
    "max_len = \n",
    "\n",
    "num_act =\n",
    "trace_prefix_len =\n",
    "trace_prefix_len ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "val_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prefix_len = 200\n",
    "trace_prefix_len = 14 # max_len + 1 (SOC or EOC)\n",
    "trace_prefix_len = 14\n",
    "num_act = 40 # number of activity labels in training set (+4): 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "val_ratio = 0.2\n",
    "\n",
    "log_prefix_len = 100\n",
    "\n",
    "log_col_name = ['concept:name', 'log_ts_pre']\n",
    "trace_col_name = ['concept:name', 'trace_ts_start', 'trace_ts_pre']\n",
    "categorical_features = ['concept:name']\n",
    "continuous_features = ['log_ts_pre', 'trace_ts_pre', 'trace_ts_start']\n",
    "case_id = 'case:concept:name'\n",
    "timestamp = 'time:timestamp'\n",
    "event_name = 'concept:name'\n",
    "event_idx = 'event_idx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare preprocessed full event log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tranform csv to dataframe\n",
    "orn_df = pd.read_csv(csv_path)\n",
    "print(orn_df.info())\n",
    "# orn_df = orn_df.loc[:,[case_id, timestamp, event_name]]\n",
    "print(\"Number of cases:\", orn_df[case_id].nunique())\n",
    "print(\"Number of activity labels:\", orn_df[event_name].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Sort dataframe by timestamp\n",
    "df = sort_log(orn_df,timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Remove duplicates\n",
    "df_withdup = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_withdup.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,[case_id, timestamp, event_name]]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Debiasing and cleaning\n",
    "df, end_timestamp = debiasing(df, start_date, end_date, max_duration, max_len, case_id, timestamp)\n",
    "print(df.info())\n",
    "print(\"Number of retaining cases:\", df[case_id].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of activity labels:\", df[event_name].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Map case ID to numbers\n",
    "df, case_id_dict= mapping_case_id(df, case_id)\n",
    "print(len(case_id_dict))\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Insert SOC and EOC rows\n",
    "df = add_soc_eoc(df, case_id, timestamp, event_name)\n",
    "print(df.info())\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create time features\n",
    "df = create_time_features(df, case_id, timestamp, event_idx)\n",
    "print(df.info())\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[event_name] == 'SOC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[event_name] == 'EOC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the summary statistics of time features\n",
    "for col in continuous_features:\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    print(col, 'Min', df[col].min())\n",
    "    print(col, 'Q1:', q1)\n",
    "    print(col, 'Mean', df[col].mean())\n",
    "    print(col, 'Q3:', q3)\n",
    "    print(col, 'Max', df[col].max())\n",
    "    print(col, 'Median', df[col].median())\n",
    "    print(col, 'Std', df[col].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Obtain max_value and min_value from training set\n",
    "## Create df containing training and validation set\n",
    "train_test_split_time, train_test_split_idx = get_train_test_split_point(df, \n",
    "                                                                         test_ratio,\n",
    "                                                                         case_id, \n",
    "                                                                         timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_test_split_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_test_split_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[train_test_split_idx-3:train_test_split_idx+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before_split = df[df[timestamp] < train_test_split_time]\n",
    "df_after_split = df[df[timestamp] >= train_test_split_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of events before train/test split\":', len(df_before_split))\n",
    "print('Number of cases before train/test split\":', df_before_split[case_id].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of events after train/test split\":', len(df_after_split))\n",
    "print('Number of cases after train/test split\":', df_after_split[case_id].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get training case list and validation case list\n",
    "train_case_list, val_case_list = get_train_val_case_list(df_before_split,\n",
    "                                                         val_ratio,\n",
    "                                                         case_id,\n",
    "                                                         timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of training cases:', len(train_case_list))\n",
    "print('Number of validation cases:', len(val_case_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get training cases, based on which max_dict, min_dict and event_name_dict will be \n",
    "training_df = df_before_split[df_before_split[case_id].isin(train_case_list)]\n",
    "val_df = df_before_split[df_before_split[case_id].isin(val_case_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of training events:', len(training_df))\n",
    "print('Number of validation events:', len(val_df))\n",
    "print(\"Number of activity labels in training_df:\", training_df[event_name].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get max value and min value for all continuous features from training set\n",
    "_, max_dict, min_dict = train_log_normalize(training_df, continuous_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(max_dict, 'max_dict_2019.pt')\n",
    "# torch.save(min_dict, 'min_dict_2019.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Log-normalize time featues\n",
    "df = test_log_normalize(df,\n",
    "                        max_dict,\n",
    "                        min_dict,\n",
    "                        continuous_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[event_name] == 'SOC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[event_name] == 'EOC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Map event name to numbers\n",
    "_, event_name_dict = train_mapping_event_name(training_df, event_name)\n",
    "df,test_event_name_dict = test_mapping_event_name(df, \n",
    "                             event_name_dict,\n",
    "                             event_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(event_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_event_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of activity labels:\", df[event_name].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train tensors and validation tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train_log_prefix_tensor, train_trace_prefix_tensor, train_suffix_act_tensor, train_suffix_time_tensor\n",
    "train_log_prefix_tensor = create_log_prefix(df=df,\n",
    "                                            log_prefix_len=log_prefix_len,\n",
    "                                            case_list=train_case_list,\n",
    "                                            start_idx=0,\n",
    "                                            end_idx=len(df_before_split),\n",
    "                                            num_act=num_act,\n",
    "                                            log_col_name=log_col_name,\n",
    "                                            categorical_features=categorical_features,\n",
    "                                            case_id=case_id,\n",
    "                                            event_name=event_name,\n",
    "                                           event_idx=event_idx)\n",
    "print(train_log_prefix_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trace_prefix_tensor = create_trace_prefix(df=df, \n",
    "                        trace_prefix_len=trace_prefix_len, \n",
    "                        case_list=train_case_list,\n",
    "                        start_idx=0,\n",
    "                        end_idx=len(df_before_split),\n",
    "                        num_act=num_act,\n",
    "                        trace_col_name=trace_col_name,\n",
    "                        categorical_features=categorical_features,\n",
    "                        case_id=case_id,\n",
    "                        event_name=event_name,\n",
    "                        event_idx=event_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_trace_prefix_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_suffix_act_tensor, train_suffix_time_start_tensor, train_suffix_time_pre_tensor = create_trace_suffix(df=df, \n",
    "                        trace_suffix_len=trace_suffix_len, \n",
    "                        case_list=train_case_list,\n",
    "                        start_idx=0,\n",
    "                        end_idx=len(df_before_split),\n",
    "                        trace_col_name=trace_col_name,\n",
    "                        categorical_features=categorical_features,\n",
    "                        case_id=case_id,\n",
    "                        event_name=event_name,\n",
    "                        event_idx=event_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_suffix_act_tensor.shape)\n",
    "print(train_suffix_time_start_tensor.shape)\n",
    "print(train_suffix_time_pre_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_next_act_tensor, train_log_next_time_tensor = create_log_next(df=df,\n",
    "                                            case_list=train_case_list,\n",
    "                                            start_idx=0,\n",
    "                                            end_idx=len(df_before_split),\n",
    "                                            log_col_name=log_col_name,\n",
    "                                            categorical_features=categorical_features,\n",
    "                                            case_id=case_id,\n",
    "                                            event_name=event_name,\n",
    "                                           event_idx=event_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_log_next_act_tensor.shape)\n",
    "print(train_log_next_time_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_log_prefix_tensor, 'train_log_prefix_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_trace_prefix_tensor,'train_trace_prefix_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_suffix_act_tensor, 'train_suffix_act_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_suffix_time_start_tensor, 'train_suffix_time_start_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_suffix_time_pre_tensor, 'train_suffix_time_pre_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_log_next_act_tensor, 'train_log_next_act_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_log_next_time_tensor, 'train_log_next_time_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_log_prefix_tensor = create_log_prefix(df=df,\n",
    "                                            log_prefix_len=log_prefix_len,\n",
    "                                            case_list=val_case_list,\n",
    "                                            start_idx=0,\n",
    "                                            end_idx=len(df_before_split),\n",
    "                                            num_act=num_act,\n",
    "                                            log_col_name=log_col_name,\n",
    "                                            categorical_features=categorical_features,\n",
    "                                            case_id=case_id,\n",
    "                                            event_name=event_name,\n",
    "                                           event_idx=event_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_log_prefix_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_trace_prefix_tensor = create_trace_prefix(df=df, \n",
    "                        trace_prefix_len=trace_prefix_len, \n",
    "                        case_list=val_case_list,\n",
    "                        start_idx=0,\n",
    "                        end_idx=len(df_before_split),\n",
    "                        num_act=num_act,\n",
    "                        trace_col_name=trace_col_name,\n",
    "                        categorical_features=categorical_features,\n",
    "                        case_id=case_id,\n",
    "                        event_name=event_name,\n",
    "                        event_idx=event_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_trace_prefix_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_suffix_act_tensor, val_suffix_time_start_tensor, val_suffix_time_pre_tensor = create_trace_suffix(df=df, \n",
    "                        trace_suffix_len=trace_suffix_len, \n",
    "                        case_list=val_case_list,\n",
    "                        start_idx=0,\n",
    "                        end_idx=len(df_before_split),\n",
    "                        trace_col_name=trace_col_name,\n",
    "                        categorical_features=categorical_features,\n",
    "                        case_id=case_id,\n",
    "                        event_name=event_name,\n",
    "                        event_idx=event_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_suffix_act_tensor.shape)\n",
    "print(val_suffix_time_start_tensor.shape)\n",
    "print(val_suffix_time_pre_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_log_next_act_tensor, val_log_next_time_tensor = create_log_next(df=df,\n",
    "                                            case_list=val_case_list,\n",
    "                                            start_idx=0,\n",
    "                                            end_idx=len(df_before_split),\n",
    "                                            log_col_name=log_col_name,\n",
    "                                            categorical_features=categorical_features,\n",
    "                                            case_id=case_id,\n",
    "                                            event_name=event_name,\n",
    "                                           event_idx=event_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_log_next_act_tensor.shape)\n",
    "print(val_log_next_time_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(val_log_prefix_tensor, 'val_log_prefix_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(val_trace_prefix_tensor, 'val_trace_prefix_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(val_suffix_act_tensor, 'val_suffix_act_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(val_suffix_time_start_tensor, 'val_suffix_time_start_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(val_suffix_time_pre_tensor, 'val_suffix_time_pre_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(val_log_next_act_tensor, 'val_log_next_act_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(val_log_next_time_tensor, 'val_log_next_time_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_case_list = get_discard_case_list(df, \n",
    "                          test_ratio, \n",
    "                          case_id, \n",
    "                          timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_cases = df[df[case_id].isin(discard_case_list)]\n",
    "discard_cases.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of discard cases:\", len(discard_case_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_discard = create_table_without_discard_case(df, test_ratio, case_id, timestamp)\n",
    "test_df = df_no_discard[df_no_discard[timestamp] >= train_test_split_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case_list = test_df[case_id].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_end_idx = df[df[timestamp] > end_timestamp].index[0]\n",
    "test_end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_log_prefix_tensor = create_log_prefix(df=df,\n",
    "                                            log_prefix_len=log_prefix_len,\n",
    "                                            case_list=test_case_list,\n",
    "                                            start_idx=train_test_split_idx,\n",
    "                                            end_idx=test_end_idx,\n",
    "                                            num_act=num_act,\n",
    "                                            log_col_name=log_col_name,\n",
    "                                            categorical_features=categorical_features,\n",
    "                                            case_id=case_id,\n",
    "                                            event_name=event_name,\n",
    "                                           event_idx=event_idx)\n",
    "print(test_log_prefix_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_log_prefix_tensor, 'test_log_prefix_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trace_prefix_tensor = create_trace_prefix(df=df, \n",
    "                        trace_prefix_len=trace_prefix_len, \n",
    "                        case_list=test_case_list,\n",
    "                        start_idx=train_test_split_idx,\n",
    "                        end_idx=test_end_idx,\n",
    "                        num_act=num_act,\n",
    "                        trace_col_name=trace_col_name,\n",
    "                        categorical_features=categorical_features,\n",
    "                        case_id=case_id,\n",
    "                        event_name=event_name,\n",
    "                        event_idx=event_idx)\n",
    "print(test_trace_prefix_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_trace_prefix_tensor, 'test_trace_prefix_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_suffix_act_tensor, test_suffix_time_start_tensor, \\\n",
    "    test_suffix_time_pre_tensor = create_trace_suffix(df=df, \n",
    "                        trace_suffix_len=trace_suffix_len, \n",
    "                        case_list=test_case_list,\n",
    "                        start_idx=train_test_split_idx,\n",
    "                        end_idx=test_end_idx,\n",
    "                        trace_col_name=trace_col_name,\n",
    "                        categorical_features=categorical_features,\n",
    "                        case_id=case_id,\n",
    "                        event_name=event_name,\n",
    "                        event_idx=event_idx)\n",
    "print(test_suffix_act_tensor.shape)\n",
    "print(test_suffix_time_start_tensor.shape)\n",
    "print(test_suffix_time_pre_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_suffix_act_tensor, 'test_suffix_act_tensor_0101.pt')\n",
    "torch.save(test_suffix_time_start_tensor, 'test_suffix_time_start_tensor_0101.pt')\n",
    "torch.save(test_suffix_time_pre_tensor, 'test_suffix_time_pre_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_log_next_act_tensor, test_log_next_time_tensor = create_log_next(df=df,\n",
    "                                            case_list=test_case_list,\n",
    "                                            start_idx=train_test_split_idx,\n",
    "                                            end_idx=test_end_idx,\n",
    "                                            log_col_name=log_col_name,\n",
    "                                            categorical_features=categorical_features,\n",
    "                                            case_id=case_id,\n",
    "                                            event_name=event_name,\n",
    "                                           event_idx=event_idx)\n",
    "print(test_log_next_act_tensor.shape)\n",
    "print(test_log_next_time_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_log_next_act_tensor, 'test_log_next_act_tensor_0101.pt')\n",
    "torch.save(test_log_next_time_tensor, 'test_log_next_time_tensor_0101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
